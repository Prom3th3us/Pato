kafka.brokers = "0.0.0.0:9092"
kafka.brokers = ${?KAFKA_BROKERS_LIST}

kafka.bootstrap-servers.external = "0.0.0.0:9092"

akka {
  kafka {
    producer {
      discovery-method = akka.discovery
      parallelism = 10000 //TODO changed in v2.0.0 from 10 to 10000
      close-timeout = 120s //TODO before 60s
      use-dispatcher = "akka.kafka.default-dispatcher"
      eos-commit-interval = 100ms
      close-on-producer-stop = true
      kafka-clients {
        bootstrap.servers = "localhost:9092"
        bootstrap.servers = ${?KAFKA_BROKERS_LIST}
      }
      #TODO This config was moved from code KafkaCommittablePartitionedMessageProcessor to improve Producer performance. See: https://kafka.apache.org/26/javadoc/?org/apache/kafka/clients/producer/ProducerConfig.html
      
      #Config optimized for Throughput
      buffer.memory = 50331648
      linger.ms = 50
      max.block.ms = 120000
      compression.type = lz4
      batch.zize =100000
      acks = 0
      
      #Config optimized for Latency
      #acks = 1
      #linger.ms = 0
      #compression.type = none

      interceptor.classes = io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor
    }
# // #producer-settings


    consumer {
      # Config path of Akka Discovery method
      # "akka.discovery" to use the Akka Discovery method configured for the ActorSystem
      discovery-method = akka.discovery


      #TODO This config was moved from code KafkaCommittablePartitionedMessageProcessor to improve Consumer performance. See: https://kafka.apache.org/26/javadoc/?org/apache/kafka/clients/consumer/ConsumerConfig.html

      #Config optimized for Throughput
      fetch.min.bytes = 100000
      
      #Config optimized for Latency
      #fetch.min.bytes = 1
      #fetch.max.wait.ms = 5
      
      max.poll.records = 1

      interceptor.classes = io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor

      # Tuning property of scheduled polls.
      # Controls the interval from one scheduled poll to the next.
      poll-interval = 5000ms //TODO changed from 10ms (default=50 ms)

      # Tuning property of the `KafkaConsumer.poll` parameter.
      # Note that non-zero value means that the thread that
      # is executing the stage will be blocked. See also the `wakup-timeout` setting below.
      poll-timeout = 50ms //TODO changed from 0ms (default=50 ms)

      # The stage will delay stopping the internal actor to allow processing of
      # messages already in the stream (required for successful committing).
      # Prefer use of `DrainingControl` over a large stop-timeout.
      stop-timeout = 30s

      # Duration to wait for `KafkaConsumer.close` to finish.
      close-timeout = 20s

      # If offset commit requests are not completed within this timeout
      # the returned Future is completed `CommitTimeoutException`.
      # The `Transactional.source` waits this ammount of time for the producer to mark messages as not
      # being in flight anymore as well as waiting for messages to drain, when rebalance is triggered.
      commit-timeout = 20s

      # If commits take longer than this time a warning is logged
      commit-time-warning = 1s

  

      # If set to a finite duration, the consumer will re-send the last committed offsets periodically
      # for all assigned partitions. See https://issues.apache.org/jira/browse/KAFKA-4682.
      commit-refresh-interval = infinite

      # Not used anymore (since 1.0-RC1)
      # wakeup-debug = true

      # Fully qualified config path which holds the dispatcher configuration
      # to be used by the KafkaConsumerActor. Some blocking may occur.
      use-dispatcher = "akka.kafka.default-dispatcher"

      # Properties defined by org.apache.kafka.clients.consumer.ConsumerConfig
      # can be defined in this configuration section.

#     processing {
#       guarantee = "exactly_once"
#     }

      kafka-clients {
        # Disable auto-commit by default
        enable.auto.commit = false
        bootstrap.servers = "localhost:9092"
        bootstrap.servers = ${?KAFKA_BROKERS_LIST}
        group.id = "group1"
        auto.offset.reset = "earliest"
      }
      # Time to wait for pending requests when a partition is closed
      wait-close-partition = 500ms
      # Limits the query to Kafka for a topic's position
      position-timeout = 5s
      # When using `AssignmentOffsetsForTimes` subscriptions: timeout for the
      # call to Kafka's API
      offset-for-times-timeout = 5s
      # Timeout for akka.kafka.Metadata requests
      # This value is used instead of Kafka's default from `default.api.timeout.ms`
      # which is 1 minute.
      metadata-request-timeout = 5s
      # Interval for checking that transaction was completed before closing the consumer.
      # Used in the transactional flow for exactly-once-semantics processing.
      #eos-draining-check-interval = 30ms
      eos-draining-check-interval = 10ms
      # Issue warnings when a call to a partition assignment handler method takes
      # longer than this.
      partition-handler-warning = 5s
      # Settings for checking the connection to the Kafka broker. Connection checking uses `listTopics` requests with the timeout
      # configured by `consumer.metadata-request-timeout`
      connection-checker {
      #Flag to turn on connection checker 
      enable = false
      # Amount of attempts to be performed after a first connection failure occurs
      # Required, non-negative integer
      max-retries = 3
      # Interval for the connection check. Used as the base for exponential retry.
      check-interval = 15s
      # Check interval multiplier for backoff interval
      # Required, positive number
      backoff-factor = 2.0
      }
      }
    }
  }

# The dispatcher that will be used by default by consumer and
# producer stages.
akka.kafka.default-dispatcher {
  type = "Dispatcher"
  executor = "thread-pool-executor"
  thread-pool-executor {
    fixed-pool-size = 64
  }
}